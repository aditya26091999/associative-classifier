{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AssociativeClassifier_SV_PHD.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNzuW/88G0FG6tvPMaodz5p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya26091999/AssociativeClassifier/blob/master/AssociativeClassifier_SV_PHD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Associative Classifier (Classification based on Apriori Algorithm generated rules)"
      ],
      "metadata": {
        "id": "ioDF8_kWQ6rw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Step 1 : Pre-requisite setup (Data cleaning, Transacional dataset preparation)**"
      ],
      "metadata": {
        "id": "bSdVRoLcRNUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 Installing external dependencies and libraries"
      ],
      "metadata": {
        "id": "LLD4iU9Mr5fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading external libraries\n",
        "!pip install efficient-apriori\n",
        "\n",
        "#Importing necessary dependencies and libraries\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from efficient_apriori import apriori"
      ],
      "metadata": {
        "id": "tqlhTrjaRgJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2 Fetching the dataset"
      ],
      "metadata": {
        "id": "76FrnS53r-f3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload the temporary dataset csv file to Google Colab Files section\n",
        "#Update the below method to reference the appropriate CSV File.\n",
        "original_dataset = pd.read_csv('/content/BuyComputerDataset.csv')\n",
        "print('------------------\\n#DATASET VALUES\\n------------------')\n",
        "display(original_dataset)"
      ],
      "metadata": {
        "id": "Hg7nzHcxuWSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3 Basic EDA of Dataset"
      ],
      "metadata": {
        "id": "Ntfsbz-tsCjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('------------------\\n#DATASET INFO()\\n------------------')\n",
        "original_dataset.info()\n",
        "print('\\n------------------\\n#DATASET DESCRIBE()\\n------------------')\n",
        "original_dataset.describe()"
      ],
      "metadata": {
        "id": "bPt_ez8zxoHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.4 Coverting the dataset into transactional dataset**"
      ],
      "metadata": {
        "id": "kf5Dzp3ZySbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the Target Class Label\n",
        "target_class_label = 'Buys_Computer'\n",
        "\n",
        "#Create a independent copy of the original dataset to form transactional_dataset\n",
        "transactional_dataset = original_dataset.copy(deep=True)\n",
        "\n",
        "#Create a transaction_symbol reference dataset\n",
        "transactional_symbol_reference = pd.DataFrame(columns=['Attribute', 'Value', 'Symbol','IsTarget'])\n",
        "\n",
        "#List to track non-categorical columns\n",
        "non_categorical_columns = list()\n",
        "\n",
        "#Traverse the dataset columnwise to encode columnar data into symbols for the transactional_dataset\n",
        "#Skipping the first column='RID'\n",
        "print('------------------\\n#CONVERTING TO TRANSACTIONAL DATASET\\n------------------')\n",
        "for attribute in transactional_dataset.columns:\n",
        "  attribute_dtype = transactional_dataset[attribute].dtype\n",
        "\n",
        "  if transactional_dataset[attribute].dtype == 'object':\n",
        "    unique_attribute_values = list(transactional_dataset[attribute].unique())\n",
        "    print('\\nAttribute : ' + attribute + ' is categorical with unique value set : ', unique_attribute_values)\n",
        "\n",
        "    #Transactional data encoding starts for that attribute column values\n",
        "    for index, unique_val in enumerate(unique_attribute_values):\n",
        "      transaction_symbol = attribute[:2] + '_' +str(index)\n",
        "      transactional_symbol_reference = transactional_symbol_reference.append({'Attribute' : attribute, 'Value' : unique_val, 'Symbol' : transaction_symbol, 'IsTarget':False}, ignore_index = True)\n",
        "      transactional_dataset.loc[transactional_dataset[attribute] == unique_val, attribute] = transaction_symbol\n",
        "\n",
        "  else:\n",
        "    non_categorical_columns.append([attribute,attribute_dtype])\n",
        "\n",
        "print(\"\\n------------------\\n#CURRENT TRANSACTIONAL DATASET LOOKS LIKE THIS\\n------------------\")\n",
        "display(transactional_dataset)\n",
        "\n",
        "print(\"\\n------------------\\n#COLUMNS THAT COULDN'T BE CONVERTED\\n------------------\")\n",
        "for entry in non_categorical_columns:\n",
        "  print('\\nAttribute : ' + entry[0] + ' is of type : ', entry[1])\n",
        "\n",
        "print(\"\\n------------------\\n#WRITE CUSTOM LOGIC TO CONVERT THEM INTO CATEGORICAL\\n------------------\")\n",
        "\n",
        "#Update the 'transactional_symbol_reference' IsTarget value=True for Target Class Categories\n",
        "transactional_symbol_reference.loc[transactional_symbol_reference['Attribute'] == target_class_label , 'IsTarget'] = True"
      ],
      "metadata": {
        "id": "hJm3bXRryRSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.5 Custom Logic for converting Non-Categorical Columns into Categorical**"
      ],
      "metadata": {
        "id": "u3kU1AzJAE9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.5.1 For Age Attribute"
      ],
      "metadata": {
        "id": "Yp9HCMuFPzsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Custom Logic to convert Age Column into Categorical Values\n",
        "\n",
        "#Defining the Category labels for Age Column and adding entries to 'transactional_symbol_reference' dataset\n",
        "age_attribute_categories = {\n",
        "    \"AttributeName\":\"Age\",\n",
        "    \"CategoryValues\" : [\"<=30\",\"31...40\",\">40\"]\n",
        "}\n",
        "\n",
        "#Automatic generation of transaction symbols for 'transaction_symbol_reference' dataset\n",
        "attribute = age_attribute_categories['AttributeName']\n",
        "for index, unique_val in enumerate(age_attribute_categories['CategoryValues']):\n",
        "  transaction_symbol = attribute[:2] + '_' +str(index)\n",
        "  transactional_symbol_reference = transactional_symbol_reference.append({'Attribute' : attribute, 'Value' : unique_val, 'Symbol' : transaction_symbol, 'IsTarget': False}, ignore_index = True)\n",
        "\n",
        "#Writing the rules for encoding the non-categorical values\n",
        "a = list(transactional_dataset.query('Age <= 30').index)\n",
        "b = list(transactional_dataset.query('Age >= 31 and Age<=40').index)\n",
        "c = list(transactional_dataset.query('Age > 40').index)\n",
        "\n",
        "\n",
        "#Encoding the 'transactional_dataset' - Age attribute values with transaction symbols\n",
        "transactional_dataset.loc[a, 'Age'] = 'Ag_0'\n",
        "transactional_dataset.loc[b, 'Age'] = 'Ag_1'\n",
        "transactional_dataset.loc[c, 'Age'] = 'Ag_2'\n",
        "\n",
        "print(\"\\n------------------\\n#CURRENT TRANSACTIONAL DATASET LOOKS LIKE THIS\\n------------------\")\n",
        "display(transactional_dataset)"
      ],
      "metadata": {
        "id": "vFz-SjypAC-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.6 Cleaning the Transactional_Dataset : Removing unnecessary attributes for Associate Rule Mining Calculation"
      ],
      "metadata": {
        "id": "_9OEv_Q8XNX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We need to remove RID attribute, as it is unnecessary for calculating Associate Rules\n",
        "transactional_dataset = transactional_dataset.drop('RID', axis=1)"
      ],
      "metadata": {
        "id": "NF52XAQQXJqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.7 Pre-requisites for AssociativeClassifier Completed**"
      ],
      "metadata": {
        "id": "bQItR7xjSWAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.8 Showing the completed assets**"
      ],
      "metadata": {
        "id": "A0uuQy7wSgcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('------------------\\n#AFTER DROPPING UNWANTED COLUMNS : RID\\n------------------')\n",
        "print(\"\\n------------------\\n#TRANSACTIONAL DATASET LOOKS LIKE THIS\\n------------------\")\n",
        "display(transactional_dataset)\n",
        "\n",
        "\n",
        "print(\"\\n------------------\\n#TRANSACTIONAL SYMBOL REFERENCE TABLE LOOKS LIKE THIS\\n------------------\")\n",
        "display(transactional_symbol_reference)\n",
        "\n",
        "print(\"\\n------------------\\n#List of Symbols\\n------------------\")\n",
        "list_of_symbols = list(transactional_symbol_reference['Symbol'])\n",
        "display(list_of_symbols)"
      ],
      "metadata": {
        "id": "QV0UiqB8Sms5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Step 2 : Apriori Algorithm (Generating Association Rule mining rules)**"
      ],
      "metadata": {
        "id": "OKQXYqAgTTBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1 External Library Setup\n",
        "\n",
        "*   Efficient-Apriori library needs to work with list of tuples\n",
        "*   The dataset 'transactional_dataset' is currently in Pandas Dataframe format - making it incompatible with this library\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-UY2RNctVTWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code snippet to convert 'transactional_dataset' dataframe into list of tuples\n",
        "\n",
        "transactional_dataset_tuplelist = [tuple(row) for row in transactional_dataset.values.tolist()]\n",
        "for transaction_tuple in transactional_dataset_tuplelist:\n",
        "  print(transaction_tuple)"
      ],
      "metadata": {
        "id": "F4W7tIa9TpWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 Running the Apriori Algorithm on Transactional Dataset"
      ],
      "metadata": {
        "id": "FzjcMWyJsokU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the Apriori Algorithm on generated 'transactional_dataset_tuplelist'\n",
        "# Refer this article : https://pypi.org/project/efficient-apriori/\n",
        "\n",
        "min_support = 0.1\n",
        "min_confidence = 0.6\n",
        "itemsets, rules = apriori(transactional_dataset_tuplelist, min_support=min_support, min_confidence=min_confidence)\n",
        "\n",
        "total_association_rules_count = len(rules)\n",
        "\n",
        "print('------------------\\n#APRIORI ALGORITHM STATISTICS\\n------------------\\n')\n",
        "print('------------------\\n#MIN SUPPORT SELECTED    : {}'.format(min_support))\n",
        "print('#MIN CONFIDENCE SELECTED : {}'.format(min_confidence))\n",
        "print('#TOTAL COUNT OF RULES          : {}\\n------------------'.format(total_association_rules_count))\n",
        "print('\\n------------------\\n#GENERATED RULES\\n------------------')\n",
        "for index,rule in enumerate(rules):\n",
        "  print('Rule #{} - {}'.format(index,rule))"
      ],
      "metadata": {
        "id": "ZEJ22-O5YD_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3 Selecting Valid Rules for Associative Classifier (Checking RHS of Rules)"
      ],
      "metadata": {
        "id": "ntunP14vs7Wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting only valid Rules for the Associative Classifier i.e Rules with Target Labels on Right Hand Side\n",
        "valid_target_labels = list(transactional_symbol_reference.query('IsTarget == True')['Symbol'])\n",
        "valid_rules = list(filter(lambda rule: any(x in rule.rhs for x in valid_target_labels) & (len(rule.rhs) == 1),rules))\n",
        "total_valid_rules_count = len(list(valid_rules))\n",
        "\n",
        "print('\\n------------------\\n#FOR ASSOCIATIVE CLASSIFIER')\n",
        "print('#TOTAL RULES GIVEN BY APRIORI ALGORITHM : {}'.format(total_association_rules_count))\n",
        "print('#VALID RULES FOR ASSOCIATIVE CLASSIFIER : {}\\n------------------\\n'.format(total_valid_rules_count))\n",
        "\n",
        "print('\\n------------------\\n#VALID RULES FOR ASSOCIATIVE CLASSIFIER\\n------------------')\n",
        "for index,rule in enumerate(valid_rules):\n",
        "  print('Rule #{} - {}'.format(index,rule))\n"
      ],
      "metadata": {
        "id": "oGRUOLnsY4lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Step 3 : Testing the Associative Classifier**"
      ],
      "metadata": {
        "id": "kOfsaxGut40h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 Funtion to format results of Associative Classifier"
      ],
      "metadata": {
        "id": "Wu3OjLtctoTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to show output of the Associative Classifier\n",
        "def showOutputOfAssociativeClassfier(predicted_target_class_label):\n",
        "  voting_method_predicted_class = transactional_symbol_reference.loc[transactional_symbol_reference['Symbol'] == predicted_target_class_label]\n",
        "  c = voting_method_predicted_class['Attribute'].to_string(index=False)\n",
        "  d = voting_method_predicted_class['Value'].to_string(index=False)\n",
        "\n",
        "  for i in test_data:\n",
        "    test_data_input_feature = transactional_symbol_reference.loc[transactional_symbol_reference['Symbol'] == i]\n",
        "    a = test_data_input_feature['Attribute'].to_string(index=False)\n",
        "    b = test_data_input_feature['Value'].to_string(index=False)\n",
        "    print('({}, {})'.format(a,b), end=', ')\n",
        "\n",
        "  print('==========> ({}, {})'.format(c,d)) "
      ],
      "metadata": {
        "id": "FEojcAHH9SSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2 Test Data Setup"
      ],
      "metadata": {
        "id": "0sLh2Pj9tfFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To apply valid rules to unseen test data\n",
        "#Person with (Age : <=40, Income : Medium, Student : Yes,Credit Rating: Fair)\n",
        "test_data = ('Ag_0','In_1','St_1','Cr_0')\n",
        "\n",
        "#Calculate list of invalid symbols for this test_data\n",
        "list_of_invalid_symbols = [x for x in list_of_symbols if (x not in test_data) & (x not in valid_target_labels)]\n",
        "print('------------------\\n#LIST OF INVALID SYMBOLS\\n------------------\\n')\n",
        "print(list_of_invalid_symbols)"
      ],
      "metadata": {
        "id": "7RtUI8Ohtc0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.3 Running the Associative Classifier on test data"
      ],
      "metadata": {
        "id": "peCwmeQythyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Querying the 'valid_rules' set for applicable rules on the test_data\n",
        "applicable_rules = list(filter(lambda rule: any(x in rule.lhs for x in test_data) & (rule.confidence >= min_confidence) & ~any(x in rule.lhs for x in list_of_invalid_symbols),valid_rules))\n",
        "\n",
        "total_applicable_rules_count = len(applicable_rules)\n",
        "\n",
        "print('\\n------------------\\n#FOR ASSOCIATIVE CLASSIFIER')\n",
        "print('#TOTAL RULES GIVEN BY APRIORI ALGORITHM      : {}'.format(total_association_rules_count))\n",
        "print('#VALID RULES FOR ASSOCIATIVE CLASSIFIER      : {}'.format(total_valid_rules_count))\n",
        "print('#APPLICABLE RULES FOR ASSOCIATIVE CLASSIFIER : {}\\n------------------\\n'.format(total_applicable_rules_count))\n",
        "\n",
        "\n",
        "print('\\n------------------\\n#VALID RULES FOR ASSOCIATIVE CLASSIFIER RANKED BY CONFIDENCE (DESCENDING)\\n------------------')\n",
        "# for index,rule in enumerate(applicable_rules):\n",
        "#   print('Rule #{} - {}'.format(index,rule))\n",
        "\n",
        "sorted_applicable_rules = sorted(applicable_rules, key=lambda rule: rule.confidence, reverse=True)\n",
        "for index,rule in enumerate(sorted_applicable_rules):\n",
        "  print('Rule #{} - {}'.format(index,rule))\n",
        "\n",
        "print('\\n------------------\\n#Class Prediction : Highest Confidence Method\\n------------------')\n",
        "showOutputOfAssociativeClassfier(sorted_applicable_rules[0].rhs[0])\n",
        "\n",
        "\n",
        "print('\\n------------------\\n#Class Prediction : Voting Method\\n------------------')\n",
        "predicted_target_class_list = list(map(lambda rule : rule.rhs[0],applicable_rules))\n",
        "voting_method_predicted_class_label = max(predicted_target_class_list,key=predicted_target_class_list.count)\n",
        "showOutputOfAssociativeClassfier(voting_method_predicted_class_label)"
      ],
      "metadata": {
        "id": "XzgNrlTCtT5m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}